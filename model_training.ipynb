{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcE3BCFo2ONbNUituTdnIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aysensahin/drain_project/blob/main/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Liquid Volume Detection From Drain Images"
      ],
      "metadata": {
        "id": "JdaBMndialBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Mount drive to achieve the dataset."
      ],
      "metadata": {
        "id": "LQWaUQSlAG78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PemZhX4QfAEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model Training"
      ],
      "metadata": {
        "id": "nmuyT-8WJasm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision.models.segmentation\n",
        "import torch\n",
        "import torchvision.transforms as tf\n",
        "\n",
        "learning_rate=1e-5\n",
        "width=height=900 # image width and height\n",
        "batchSize= 3\n",
        "\n",
        "train_folder=\"/content/drive/MyDrive/drain_train\"  #Add drive link of the dataset\n",
        "# Create list of images\n",
        "ListofImages=os.listdir(os.path.join(train_folder, \"Image\"))\n",
        "\n",
        "# Transform image\n",
        "transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "transformAnn=tf.Compose([tf.ToPILImage(),tf.Resize((height,width),tf.InterpolationMode.NEAREST),tf.ToTensor()])\n",
        "\n",
        "# Read image\n",
        "def ReadRandom(): # Load random image and its annotation\n",
        "    idx=np.random.randint(0,len(ListofImages)) # Select random image\n",
        "    Img=cv2.imread(os.path.join(train_folder, \"Image\", ListofImages[idx]))[:,:,0:3]\n",
        "    Filled =  cv2.imread(os.path.join(train_folder, \"Segmentation/3_Blood\", ListofImages[idx].replace(\"jpg\",\"png\")),0)  #blood\n",
        "    Vessel1 =  cv2.imread(os.path.join(train_folder, \"Segmentation/1_Drain1\", ListofImages[idx].replace(\"jpg\",\"png\")),0)  #jackson pratt drain\n",
        "    Vessel2 =  cv2.imread(os.path.join(train_folder, \"Segmentation/2_Drain2\", ListofImages[idx].replace(\"jpg\",\"png\")),0)  #hemovac drain\n",
        "    AnnotationMap = np.zeros(Img.shape[0:2],np.float32)\n",
        "    if Vessel1 is not None:  AnnotationMap[ Vessel1 == 1 ] = 1\n",
        "    if Vessel2 is not None:  AnnotationMap[ Vessel2 == 1 ] = 2\n",
        "    if Filled is not None:  AnnotationMap[ Filled  == 1 ] = 3\n",
        "    Img=transformImg(Img)\n",
        "    AnnotationMap=transformAnn(AnnotationMap)\n",
        "    return Img,AnnotationMap\n",
        "\n",
        "# Load batch of images\n",
        "def LoadBatch(): # Load batch of images\n",
        "    images = torch.zeros([batchSize,3,height,width])\n",
        "    ann = torch.zeros([batchSize, height, width])\n",
        "    for i in range(batchSize):\n",
        "        images[i],ann[i]=ReadRandom()\n",
        "    return images, ann\n",
        "\n",
        "# Load and set net and optimizer\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True) # Load net\n",
        "Net.classifier[4] = torch.nn.Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 4 classes which are blood,drain1,drain2,background\n",
        "Net=Net.to(device)\n",
        "optimizer=torch.optim.Adam(params=Net.parameters(),lr=learning_rate) # Create adam optimizer\n",
        "\n",
        "# Train\n",
        "for itr in range(10000): # Training loop\n",
        "   images,ann=LoadBatch() # Load training batch\n",
        "   images=torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
        "   ann = torch.autograd.Variable(ann, requires_grad=False).to(device) # Load annotation\n",
        "   Prediction=Net(images)['out'] # Make prediction\n",
        "   Net.zero_grad()\n",
        "   criterion = torch.nn.CrossEntropyLoss() # Set loss function\n",
        "   Loss=criterion(Prediction,ann.long()) # Calculate cross entropy loss\n",
        "   Loss.backward() # Backpropogate loss\n",
        "   optimizer.step() # Apply gradient descent change to weight\n",
        "   seg = torch.argmax(Prediction[0], 0).cpu().detach().numpy()  # Get  prediction classes\n",
        "   print(itr,\") Loss=\",Loss.data.cpu().numpy())\n",
        "   if itr % 1000 == 0: #Save model weights\n",
        "        print(\"Saving Model\" +str(itr) + \".torch\")\n",
        "        torch.save(Net.state_dict(),   str(itr) + \".torch\")"
      ],
      "metadata": {
        "id": "5B_6Vde8_476"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(Net.state_dict(), \"9999.torch\")"
      ],
      "metadata": {
        "id": "GbkOKmmhhWn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Obtaining segmented output images using trained model"
      ],
      "metadata": {
        "id": "V3G4104MKYFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torchvision.models.segmentation\n",
        "import torch\n",
        "import torchvision.transforms as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "modelPath = \"/content/drive/MyDrive/trainedmodel.torch\"   #Path to trained model (9999.torch)\n",
        "imagePath = \"/content/image.jpg\"   #Path of original image\n",
        "height=width=900\n",
        "transformImg = tf.Compose([tf.ToPILImage(), tf.Resize((height, width)), tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
        "Net.classifier[4] = torch.nn.Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
        "Net = Net.to(device)  # Set net to GPU or CPU\n",
        "Net.load_state_dict(torch.load(modelPath)) # Load trained model\n",
        "Net.eval() # Set to evaluation mode\n",
        "Img = cv2.imread(imagePath) # load test image\n",
        "height_orgin , width_orgin ,d = Img.shape # Get image original size\n",
        "plt.imshow(Img[:,:,::-1])  # Show imageplt.show()\n",
        "Img = transformImg(Img)  # Transform to pytorch\n",
        "Img = torch.autograd.Variable(Img, requires_grad=False).to(device).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    Prediction = Net(Img)['out']  # Run net\n",
        "# resize to original size\n",
        "Prediction = tf.Resize((height_orgin,width_orgin))(Prediction[0])\n",
        "#Convert probability to class map\n",
        "seg = torch.argmax(Prediction, 0).cpu().detach().numpy()\n",
        "plt.imshow(seg)  # display image\n",
        "plt.imsave('/content/imagesegmented.png', seg)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0R3qzI_LG_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Detect volume with pixel counting\n",
        "\n"
      ],
      "metadata": {
        "id": "kWlmRaYkjfHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import math\n",
        "\n",
        "img = Image.open('/content/IMG_0408segmented.png')\n",
        "\n",
        "drain = 0\n",
        "blood = 0\n",
        "\n",
        "for pixel in img.getdata():\n",
        "    if pixel == (48, 103, 141, 255): # (32, 144, 140, 255) drain2 // (48, 103, 141, 255) drain1\n",
        "        drain += 1\n",
        "    elif pixel == (253, 231, 36, 255): # (253, 231, 36, 255)\n",
        "        blood += 1\n",
        "volume = math.floor(blood / (blood + drain) * 267)  #390 for drain2 without bottom //  267 for drain1\n",
        "print(f\"Estimated volume of blood is {volume}ml\")"
      ],
      "metadata": {
        "id": "0-m2fMvMjnYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}